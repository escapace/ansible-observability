#!/usr/bin/env bash

set -e
set -u
set -o pipefail

umask 027

SCRIPT_NAME=
SCRIPT_NAME="$(basename "$0")"

declare -A OBSERVABILITY_TAGS

TELEMETRY_ENVIRONMENT_FILE_PATH="/etc/sysconfig/telemetry-environment"

function wrap() {
  local strings="${1}"

  local length
  local cols
  local width
  local sep="|"

  length="$(echo -n "${strings}" | awk -F '|' '{print $1}' | awk '{ print length }' | sort -n | tail -1)"
  cols="$(tput cols)"
  local cols_minus_four="$((cols - 4))"

  if [[ "$((cols_minus_four / length))" -ge 2 ]]; then
    if [[ "$((cols - length - 4))" -ge 80 ]]; then
      width="80"
    else
      width="$((cols - length - 4))"
    fi

    echo -e "${strings}" |
      fold -s -w "${width}" |
      sed -e "/--/! s|^| \||g" |
      column -t -s '|' |
      sed 's/^/  /'
  else
    local lines
    local line
    readarray -t lines <<<"${strings}"
    local option
    local description

    if [[ "${cols}" -ge 80 ]]; then
      width="78"
    else
      width="$((cols - 2))"
    fi

    for line in "${lines[@]}"; do
      # shellcheck disable=SC1073,SC2295
      option="${line%%$sep*}"
      # shellcheck disable=SC1073,SC2295
      description="${line#*$sep}"

      echo "${option}"
      echo
      echo "${description}" | fold -s -w "${width}" | sed 's/^/  /'
      echo
    done
  fi
}

function print_usage() {
  echo
  echo "Usage: ${SCRIPT_NAME} [OPTIONS]"
  echo
  echo "This script is used to configure observability on a AWS EC2 server."
  echo
  echo "Options:"
  echo
  wrap "$(
    echo -e "--role|The instance role, one of \"server\", \"client\" or \"bastion\"."
    echo -e "--amp-workspace-id|Amazon Managed Service for Prometheus Workspace ID."
    echo -e "--cloudwatch-group-name|CloudWatch log group name."
    echo -e "--enable-cloudflared|Collect cloudflare tunnel client metrics."
    echo -e "--enable-consul|Collect consul metrics."
    echo -e "--enable-esm|Collect consul-esm metrics."
    echo -e "--enable-kresd|Collect knot resolver metrics."
    echo -e "--enable-nomad|Collect nomad metrics."
    echo -e "--enable-service-discovery|Discover scrape targets running on this node."
    echo -e "--enable-vault|Collect vault metrics."
    echo -e "--metrics-scrape-interval|The interval between scrapes, in seconds."
    echo -e "--logs-sample-rate|The rate at which low priority logs are forwarded, for example 10 means 1 out of every 10 events are forwarded and the rest are dropped."
    echo -e "--secrets-bucket-name|AWS S3 secrets bucket name."
    echo -e "--tag|Tag vector logs and metrics. Repeat this option for additional tags."
  )"
  echo
}

function log() {
  local -r level="$1"
  local -r message="$2"
  local timestamp

  timestamp="$(date +"%Y-%m-%d %H:%M:%S")"

  echo >&2 -e "${timestamp} [${level}] [$SCRIPT_NAME] ${message}"
}

function log_info() {
  local -r message="$1"
  log "INFO" "$message"
}

function log_warn() {
  local -r message="$1"
  log "WARN" "$message"
}

function log_error() {
  local -r message="$1"
  log "ERROR" "$message"
}

function assert_not_empty() {
  local -r arg_name="$1"
  local -r arg_value="$2"

  if [[ -z "$arg_value" ]]; then
    log_error "The value for '$arg_name' cannot be empty"
    print_usage
    exit 1
  fi
}

function assert_is_installed() {
  local -r name="$1"

  if [[ ! $(command -v "${name}") ]]; then
    log_error "The binary '$name' is required by this script but is not installed or in the system's PATH."
    exit 1
  fi
}

function parse_tag() {
  local string="${1}"
  local -r regex="^([a-zA-Z_][a-zA-Z0-9_]*)=([a-zA-Z_:][a-zA-Z0-9_:]*)"
  local name
  local value

  if [[ "${string}" =~ ${regex} && "${#BASH_REMATCH[@]}" == "3" ]]; then
    name="${BASH_REMATCH[1]}"
    value="${BASH_REMATCH[2]}"
    OBSERVABILITY_TAGS["${name}"]="${value}"
  else
    log_error "Unable to parse tag: ${string}"
  fi
}

function join() {
  local d=${1-} f=${2-}

  if shift 2; then
    printf %s "$f" "${@/#/$d}"
  fi
}

function get_object_value() {
  local -r secrets_bucket_name="$1"
  local -r source="$2"

  local -r key="${EC2_INSTANCE_REGION}/${source}"

  log_info "Downloading ${key}"

  aws s3 cp --quiet \
    "s3://${secrets_bucket_name}/${key}" /dev/stdout || exit 1
}

function write_vector_configuration() {
  local -r secrets_bucket_name="${1}"
  local -r enable_kresd="${2}"
  local -r enable_consul="${3}"
  local -r enable_nomad="${4}"
  local -r enable_cloudflared="${5}"
  local -r enable_esm="${6}"
  local -r enable_vault="${7}"

  local logs_metadata_sample_exclude
  local logs_metadata_transform
  local metrics_metadata_filter

  logs_metadata_sample_exclude="$(get_object_value "${secrets_bucket_name}" "${role}/telemetry/vector-logs-sample-exclude")"
  logs_metadata_transform="$(get_object_value "${secrets_bucket_name}" "${role}/telemetry/vector-logs-remap")"
  metrics_metadata_filter="$(get_object_value "${secrets_bucket_name}" "${role}/telemetry/vector-metrics-filter")"

  local -r vector_configuration_path="/etc/vector/vector.toml"
  local -r vector_telemetry_environment_path="/etc/systemd/system/vector.service.d/telemetry-environment.conf"

  local metrics_metadata_tags

  metrics_metadata_tags=$(
    for name in "${!OBSERVABILITY_TAGS[@]}"; do
      echo ".tags.${name}=\"${OBSERVABILITY_TAGS[$name]:-false}\""
    done
  )

  local logs_metadata_tags

  logs_metadata_tags=$(
    for name in "${!OBSERVABILITY_TAGS[@]}"; do
      echo ".${name}=\"${OBSERVABILITY_TAGS[$name]:-false}\""
    done
  )

  local vector_configuration_kresd=""
  local vector_configuration_consul=""
  local vector_configuration_nomad=""
  local vector_configuration_cloudflared=""
  local vector_configuration_esm=""
  local vector_configuration_vault=""
  local vector_sources_list_array=("\"transform-metrics-amp-proxy\"" "\"transform-metrics-node-exporter\"" "\"transform-metrics-vector\"")

  if [[ "${enable_consul}" == "true" ]]; then
    vector_sources_list_array+=("\"transform-metrics-consul*\"")

    vector_configuration_consul=$(
      cat <<EOF

## CONSUL

[sources.source-metrics-consul]
type = "prometheus_scrape"
endpoints = ["http://[::1]:8500/v1/agent/metrics?format=prometheus"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[sources.source-metrics-consul.auth]
token = "\${CONSUL_HTTP_TOKEN}"
strategy = "bearer"

[transforms.transform-metrics-consul]
type = "remap"
inputs = ["source-metrics-consul"]
source = '''
.tags.service = "consul"
.tags.tenant  = "infrastructure"
'''

EOF
    )
  fi

  if [[ "${enable_esm}" == "true" ]]; then
    vector_sources_list_array+=("\"transform-metrics-esm\"")

    vector_configuration_esm=$(
      cat <<EOF

## esm

[sources.source-metrics-esm]
type = "prometheus_scrape"
endpoints = ["http://[::1]:8559/metrics"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-esm]
type = "remap"
inputs = ["source-metrics-esm"]
source = '''
.tags.service = "esm"
.tags.tenant  = "infrastructure"
'''

EOF
    )
  fi

  if [[ "${enable_kresd}" == "true" ]]; then
    vector_sources_list_array+=("\"transform-metrics-kresd\"")

    vector_configuration_kresd=$(
      cat <<EOF

## KRESD

[sources.source-metrics-kresd]
type = "prometheus_scrape"
endpoints = ["http://[::1]:8453/metrics"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-kresd]
type = "remap"
inputs = ["source-metrics-kresd"]
source = '''
.tags.service = "kresd"
.tags.tenant  = "infrastructure"
'''

EOF
    )
  fi

  if [[ "${enable_nomad}" == "true" ]]; then
    vector_sources_list_array+=("\"transform-metrics-nomad\"")

    vector_configuration_nomad=$(
      cat <<EOF

## NOMAD

[sources.source-metrics-nomad]
type = "prometheus_scrape"
# TODO: vector fails tls verification with [::1]
endpoints = ["https://localhost:4646/v1/metrics?format=prometheus"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-nomad]
type = "remap"
inputs = ["source-metrics-nomad"]
source = '''
.tags.service = "nomad"
.tags.tenant  = "infrastructure"
'''

EOF
    )
  fi

  if [[ "${enable_cloudflared}" == "true" ]]; then
    vector_sources_list_array+=("\"transform-metrics-cloudflared\"")

    vector_configuration_cloudflared=$(
      cat <<EOF

## cloudflared

[sources.source-metrics-cloudflared]
type = "prometheus_scrape"
endpoints = ["http://[::1]:9301/metrics"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-cloudflared]
type = "remap"
inputs = ["source-metrics-cloudflared"]
source = '''
.tags.service = "cloudflared"
.tags.tenant  = "infrastructure"
'''

EOF
    )
  fi

  if [[ "${enable_vault}" == "true" ]]; then
    vector_sources_list_array+=("\"transform-metrics-vault\"")

    vector_configuration_vault=$(
      cat <<EOF

## vault

[sources.source-metrics-vault]
type = "prometheus_scrape"
endpoints = ["https://localhost:8200/v1/sys/metrics?format=prometheus"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-vault]
type = "remap"
inputs = ["source-metrics-vault"]
source = '''
.tags.service = "vault"
.tags.tenant  = "infrastructure"
'''

EOF
    )
  fi

  local vector_sources_list
  vector_sources_list="$(join ", " "${vector_sources_list_array[@]}")"

  local -r vector_configuration=$(
    cat <<EOF
[healthchecks]
enabled = true
require_healthy = false

[api]
enabled = false
address = "127.0.0.1:8686"

# JOURNALD

[sources.source-logs-journald]
type = "journald"
current_boot_only = true

## NODE EXPORTER

[sources.source-metrics-node-exporter]
type = "prometheus_scrape"
endpoints = ["http://[::1]:9100/metrics"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-node-exporter]
type = "remap"
inputs = ["source-metrics-node-exporter"]
source = '''
.tags.service = "node-exporter"
.tags.tenant  = "infrastructure"
'''

## VECTOR

[sources.source-metrics-vector]
type = "internal_metrics"
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-vector]
type = "remap"
inputs = ["source-metrics-vector"]
source = '''
.tags.service = "vector"
.tags.tenant  = "infrastructure"
'''

## AMP-PROXY

[sources.source-metrics-amp-proxy]
type = "prometheus_scrape"
endpoints = ["http://[::1]:9901/stats/prometheus"]
scrape_interval_secs = \${VECTOR_METRICS_SCRAPE_INTERVAL:-120}

[transforms.transform-metrics-amp-proxy]
type = "remap"
inputs = ["source-metrics-amp-proxy"]
source = '''
.tags.service = "amp-proxy"
.tags.tenant  = "infrastructure"
'''

${vector_configuration_kresd}
${vector_configuration_consul}
${vector_configuration_nomad}
${vector_configuration_cloudflared}
${vector_configuration_esm}
${vector_configuration_vault}

## ---

[transforms.transform-metrics-remap]
type = "remap"
inputs = [${vector_sources_list}]
source = '''
.tags.region = get_env_var!("EC2_INSTANCE_REGION")
.tags.instance_id = get_env_var!("EC2_INSTANCE_ID")
.tags.instance_type = get_env_var!("EC2_INSTANCE_TYPE")
.tags.availability_zone = get_env_var!("EC2_INSTANCE_AVAILABILITY_ZONE")
del(.tags.host)
.tags.host = get_hostname!()
${metrics_metadata_tags}
'''

[transforms.transform-logs-remap]
type = "remap"
inputs = ["source-logs-journald"]
source = '''
value = .
${logs_metadata_transform}
${logs_metadata_tags}
'''

[transforms.transform-logs-sample]
type = "sample"
inputs = ["transform-logs-remap"]
rate = \${VECTOR_LOGS_SAMPLE_RATE:-10}
exclude.type = "vrl"
exclude.source = '''
${logs_metadata_sample_exclude}
'''

## ---

# https://github.com/hashicorp/consul/blob/main/ui/packages/consul-ui/vendor/metrics-providers/prometheus.js
[transforms.transform-metrics-filter]
type = "filter"
inputs = [
  "transform-metrics-remap"
]
condition.type = "vrl"
condition.source = '''
${metrics_metadata_filter}
'''

[sinks.sink-prometheus]
type = "prometheus_remote_write"
endpoint = "http://[::1]:9201/api/v1/remote_write"
healthcheck = false
request.concurrency = "adaptive"
inputs = [
  "transform-metrics-filter"
]

[sinks.sink-cloudwatch]
type = "aws_cloudwatch_logs"
create_missing_group = true
create_missing_stream = true
group_name = "\${AWS_CLOUDWATCH_GROUP_NAME}"
compression = "gzip"
region = "${EC2_INSTANCE_REGION}"
encoding.codec = "json"
stream_name = "{{ instance_id }}"
request.concurrency = "adaptive"
inputs = [
  "transform-logs-sample"
]

EOF
  )

  log_info "Writing ${vector_configuration_path}"

  echo -e "${vector_configuration}" >"${vector_configuration_path}"

  chown vector:vector "${vector_configuration_path}"
  chmod 640 "${vector_configuration_path}"

  mkdir -p "$(dirname "${vector_telemetry_environment_path}")"
  chown root:root "$(dirname "${vector_telemetry_environment_path}")"
  chmod 755 "$(dirname "${vector_telemetry_environment_path}")"

  log_info "Writing ${vector_telemetry_environment_path}"

  local -r vector_telemetry_environment=$(
    cat <<EOF
[Unit]
After=consul-online.target
Wants=consul-online.target
After=vault-online.target
Wants=vault-online.target
After=nomad-online.target
Wants=nomad-online.target
After=kresd.target
Wants=kresd.target
After=node-exporter.service
Wants=node-exporter.service

[Service]
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
EOF
  )

  echo -e "${vector_telemetry_environment}" >"${vector_telemetry_environment_path}"
  chown root:root "${vector_telemetry_environment_path}"
  chmod 644 "${vector_telemetry_environment_path}"
}

function write_telemetry_environment() {
  local -r role="${1}"
  local -r secrets_bucket_name="${2}"
  local -r metrics_scrape_interval="${3}"
  local -r logs_sample_rate="${4}"
  local -r cloudwatch_group_name="${5}"

  local -r telemetry_environment_file_path="${TELEMETRY_ENVIRONMENT_FILE_PATH}"

  local aws_access_key_id
  local aws_secret_access_key

  aws_access_key_id="$(get_object_value "${secrets_bucket_name}" "${role}/telemetry/aws-access-key-id-telemetry")"
  aws_secret_access_key="$(get_object_value "${secrets_bucket_name}" "${role}/telemetry/aws-secret-access-key-telemetry")"

  local consul_http_token

  consul_http_token="$(get_object_value "${secrets_bucket_name}" "${role}/telemetry/consul-acl-token-consul-telemetry")"

  local -r telemetry_environment=$(
    cat <<EOF
AWS_ACCESS_KEY_ID=${aws_access_key_id}
AWS_SECRET_ACCESS_KEY=${aws_secret_access_key}
AWS_CLOUDWATCH_GROUP_NAME=${cloudwatch_group_name}
VECTOR_METRICS_SCRAPE_INTERVAL=${metrics_scrape_interval}
VECTOR_LOGS_SAMPLE_RATE=${logs_sample_rate}
CONSUL_HTTP_TOKEN=${consul_http_token}
EOF
  )

  log_info "Writing ${telemetry_environment_file_path}"

  echo -e "${telemetry_environment}" >"${telemetry_environment_file_path}"

  chown root:root "${telemetry_environment_file_path}"
  chmod 640 "${telemetry_environment_file_path}"

  setfacl -m u:vector:r "${telemetry_environment_file_path}"
  setfacl -m u:amp-proxy:r "${telemetry_environment_file_path}"
}

function write_amp_proxy_configuration() {
  local -r workspace_id="${1}"
  local -r region="${EC2_INSTANCE_REGION}"

  local -r amp_proxy_configuration_path="/opt/amp-proxy/config/default.yml"
  local -r amp_proxy_service_configuration_path="/etc/systemd/system/amp-proxy.service"

  local -r amp_proxy_configuration=$(
    cat <<EOF
admin:
  address:
    socket_address: { address: "::1", port_value: 9901 }

static_resources:
  listeners:
    - address:
        socket_address:
          protocol: "TCP"
          address: "::1"
          port_value: 9201
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                codec_type: AUTO
                stat_prefix: amp-proxy
                strip_any_host_port: true
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: amp-proxy
                      domains: ['*']
                      routes:
                        - name: amp-proxy
                          match:
                            prefix: /
                          route:
                            cluster: amp-proxy
                http_filters:
                  - name: envoy.filters.http.lua
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua
                      inline_code: |
                        -- Called on the request path.
                        function envoy_on_request(request_handle)
                          local path = request_handle:headers():get(":path")
                          request_handle:headers():replace(":path", "/workspaces/${workspace_id}" .. path)
                        end
                        -- Called on the response path.
                        function envoy_on_response(response_handle)
                        end
                  - name: envoy.filters.http.aws_request_signing
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.aws_request_signing.v3.AwsRequestSigning
                      service_name: aps
                      region: ${region}
                      host_rewrite: aps-workspaces.${region}.amazonaws.com
                      match_excluded_headers:
                        - prefix: x-envoy
                        - prefix: x-forwarded
                        - prefix: cf-
                        - prefix: sec-
                        - exact: upgrade-insecure-requests
                        - exact: user-agent
                        - exact: cookie
                        - exact: priority
                        - exact: cdn-loop
                        - exact: x-amzn-trace-id

                  - name: envoy.filters.http.router
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
    - name: amp-proxy
      connect_timeout: 0.25s
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
      load_assignment:
        cluster_name: amp-proxy
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: aps-workspaces.${region}.amazonaws.com
                      port_value: 443
EOF
  )

  local -r amp_proxy_service_configuration=$(
    cat <<EOF
[Unit]
Description=Amazon Managed Service for Prometheus Signing Proxy
After=network-online.target
Wants=network-online.target

[Service]
User=amp-proxy
Group=amp-proxy
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
ExecStart=/usr/bin/envoy --use-dynamic-base-id --disable-hot-restart --log-level error --config-path "${amp_proxy_configuration_path}"
KillMode=mixed
LimitNOFILE=640000
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
WantedBy=vector.service

EOF
  )

  log_info "Writing ${amp_proxy_configuration_path}"
  log_info "Writing ${amp_proxy_service_configuration_path}"

  echo -e "$amp_proxy_configuration" >"$amp_proxy_configuration_path"
  chown amp-proxy:amp-proxy "${amp_proxy_configuration_path}"
  chmod 644 "${amp_proxy_configuration_path}"

  echo -e "$amp_proxy_service_configuration" >"$amp_proxy_service_configuration_path"
  chown root:root "${amp_proxy_service_configuration_path}"
  chmod 644 "${amp_proxy_service_configuration_path}"
}

function write_service_discovery_configuration() {
  local -r vector_service_discovery_service_path="/etc/systemd/system/vector-service-discovery.service"
  local -r vector_service_discovery_template_path="/etc/vector/vector.d/service-disccovery.ctmpl"
  local -r vector_service_discovery_configuration_path="/etc/vector/vector.d/service-disccovery.toml"

  local -r vector_service_discovery_service=$(
    cat <<EOF
[Unit]
Description=Vector Service Discovery
After=network-online.target
Wants=network-online.target
After=vector.service
Wants=vector.service
After=consul-online.target
Wants=consul-online.target

[Service]
User=vector
Group=vector
SuccessExitStatus=12
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
ExecStart=consul-template -log-level=err -reload-signal=SIGHUP -kill-signal=SIGINT -consul-retry -consul-retry-attempts=0 -consul-retry-backoff=250ms -consul-retry-max-backoff=0 -template="${vector_service_discovery_template_path}:${vector_service_discovery_configuration_path}"
ExecReload=/bin/kill -HUP \$MAINPID
KillSignal=SIGINT
LimitNOFILE=640000
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target

EOF
  )

  local -r vector_service_discovery_template=$(
    cat <<'EOF'
{{- with node -}}
{{- range .Services -}}
{{- if and (.Service | regexMatch "-sidecar-proxy" | not) (index .Meta "prometheus_endpoints") -}}
{{- $service := . -}}
{{- $value := sprig_compact (sprig_uniq (.Meta.prometheus_endpoints | parseJSON)) -}}
{{- range $value -}}
{{- $endpoint := . | sprig_replace "SERVICE_ADDRESS" $service.Address | sprig_replace "SERVICE_PORT" ($service.Port | sprig_toString) | sprig_replace "SERVICE_ID" $service.ID -}}
{{- scratch.MapSet "endpoints" $endpoint $service -}}
{{- end -}}
{{- end -}}
{{- end -}}
{{- end -}}

{{ range sprig_keys (scratch.Get "endpoints") }}
{{- $service := index (scratch.Get "endpoints") . -}}
{{- $name := sprig_list (sprig_kebabcase $service.Service) (sprig_sha256sum .) | sprig_join "-" -}}
{{- $scrape_interval := sprig_default "${VECTOR_METRICS_SCRAPE_INTERVAL:-120}" $service.Meta.prometheus_scrape_interval -}}
{{- $tags := sprig_default "{}" $service.Meta.prometheus_labels | parseJSON -}}
# {{ $name }}

[sources.source-metrics-consul-{{ $name }}]
type = "prometheus_scrape"
endpoints = [{{ . | toJSON }}]
scrape_interval_secs = {{ $scrape_interval }}

[transforms.transform-metrics-consul-{{ $name }}]
type = "remap"
inputs = ["source-metrics-consul-{{ $name }}"]
source = '''
{{ range $key, $value := $tags -}}{{- if not (sprig_empty $value) -}}
.tags.{{ sprig_snakecase $key }} = "{{ $value | sprig_toString }}"
{{ end -}}{{- end -}}
'''

{{ end }}

EOF
  )

  echo -e "$vector_service_discovery_service" >"$vector_service_discovery_service_path"
  chown root:root "${vector_service_discovery_service_path}"
  chmod 644 "${vector_service_discovery_service_path}"

  echo -e "$vector_service_discovery_template" >"$vector_service_discovery_template_path"
  chown vector:vector "${vector_service_discovery_template_path}"
  chmod 640 "${vector_service_discovery_template_path}"
}

function configure_node_exporter() {
  local node_exporter_options_path="/opt/node-exporter/config/options"

  # '--collector.conntrack'

  local node_exporter_options_array=(
    '--collector.cpu'
    '--collector.disable-defaults'
    '--collector.diskstats'
    '--collector.diskstats.device-exclude="^(dm-|ram|loop|fd|(h|s|v|xv)d[a-z]|nvme[0-9]+n[0-9]+p)[0-9]+\$"'
    '--collector.entropy'
    '--collector.filesystem'
    '--collector.filesystem.fs-types-exclude="^(tmpfs|systemd-1|efivarfs|autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)\$"'
    '--collector.filesystem.mount-points-exclude="^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)(\$|/)"'
    '--collector.loadavg'
    '--collector.meminfo'
    '--collector.netclass'
    '--collector.netclass.ignored-devices="^(nomad|docker.+|lo|dummy.+|veth.+)\$"'
    '--collector.netdev'
    '--collector.netdev.device-exclude="^(nomad|docker.+|lo|dummy.+|veth.+)\$"'
    '--collector.pressure'
    '--collector.processes'
    '--collector.schedstat'
    '--collector.stat'
    '--collector.systemd'
    '--collector.systemd.unit-include="(amp-proxy.service|chronyd.service|cloudflared.service|consul-bootstrap.service|consul-esm.service|consul-online.service|consul-snapshot.service|consul-terraform-sync.service|consul.service|containerd.service|docker.service|ec2-environment.service|ferm.service|kres-cache-gc.service|kresd@.+|node-exporter.service|nomad-bootstrap.service|nomad-online.service|nomad-snapshot.service|nomad.service|sshd.service|storage-setup.service|systemd-networkd.service|tailscaled.service|vault-bootstrap.service|vault-online.service|vault-snapshot.service|vault.service|vector-service-discovery.service|vector.service)"'
    '--collector.timex'
    '--collector.vmstat'
    '--web.listen-address="[::1]:9100"'
  )

  local node_exporter_options
  node_exporter_options="OPTIONS=$(join " " "${node_exporter_options_array[@]}")"

  echo -e "$node_exporter_options" >"${node_exporter_options_path}"
  chown node-exporter:node-exporter "${node_exporter_options_path}"
  chmod 640 "${node_exporter_options_path}"
}

function run() {
  if [[ ! -f "/etc/sysconfig/ec2-environment" ]]; then
    print_usage

    log_error "/etc/sysconfig/ec2-environment: No such file"

    exit 1
  fi

  set -o allexport
  # shellcheck disable=SC1091
  source "/etc/sysconfig/ec2-environment"
  set +o allexport

  local role=""
  local secrets_bucket_name=""
  local cloudwatch_group_name=""
  local amp_workspace_id=""
  local metrics_scrape_interval="120"
  local logs_sample_rate="10"
  local enable_kresd="false"
  local enable_consul="false"
  local enable_esm="false"
  local enable_nomad="false"
  local enable_vault="false"
  local enable_cloudflared="false"
  local enable_service_discovery="false"

  while [[ $# -gt 0 ]]; do
    local key="$1"

    case "$key" in
    --role)
      assert_not_empty "$key" "$2"
      role="$2"
      shift
      ;;
    --metrics-scrape-interval)
      assert_not_empty "$key" "$2"
      metrics_scrape_interval="$2"
      shift
      ;;
    --logs-sample-rate)
      assert_not_empty "$key" "$2"
      logs_sample_rate="$2"
      shift
      ;;
    --secrets-bucket-name)
      assert_not_empty "$key" "$2"
      secrets_bucket_name="$2"
      shift
      ;;
    --amp-workspace-id)
      assert_not_empty "$key" "$2"
      amp_workspace_id="$2"
      shift
      ;;
    --cloudwatch-group-name)
      assert_not_empty "$key" "$2"
      cloudwatch_group_name="$2"
      shift
      ;;
    --tag)
      assert_not_empty "$key" "$2"
      parse_tag "${2}"
      shift
      ;;
    --enable-kresd)
      enable_kresd=true
      ;;
    --enable-consul)
      enable_consul=true
      ;;
    --enable-esm)
      enable_esm=true
      ;;
    --enable-nomad)
      enable_nomad=true
      ;;
    --enable-vault)
      enable_vault=true
      ;;
    --enable-cloudflared)
      enable_cloudflared=true
      ;;
    --enable-service-discovery)
      enable_service_discovery=true
      ;;
    --help)
      print_usage
      exit
      ;;
    *)
      log_error "Unrecognized argument: $key"
      print_usage
      exit 1
      ;;
    esac

    shift
  done

  assert_not_empty "--secrets-bucket-name" "${secrets_bucket_name}"
  assert_not_empty "--cloudwatch-group-name" "${cloudwatch_group_name}"
  assert_not_empty "--amp-workspace-id" "${amp_workspace_id}"
  assert_not_empty "--role" "$role"

  if ! [[ "$role" == "server" || "$role" == "client" || "$role" == "bastion" ]]; then
    log_error "Unrecognized value for the --role flag."
    exit 1
  fi

  if ! [[ "${metrics_scrape_interval}" =~ ^[0-9]+$ ]]; then
    log_error "--metrics-scrape-interval must be a number."
    print_usage
    exit 1
  fi

  if ! [[ "${logs_sample_rate}" =~ ^[0-9]+$ ]]; then
    log_error "--logs-sample-rate must be a number."
    print_usage
    exit 1
  fi

  assert_is_installed "systemctl"
  assert_is_installed "jq"
  assert_is_installed "awk"

  if [[ "${enable_service_discovery}" == "true" ]]; then
    assert_is_installed "consul-template"
  fi

  configure_node_exporter

  write_telemetry_environment \
    "${role}" \
    "${secrets_bucket_name}" \
    "${metrics_scrape_interval}" \
    "${logs_sample_rate}" \
    "${cloudwatch_group_name}"

  write_amp_proxy_configuration \
    "${amp_workspace_id}"

  write_vector_configuration \
    "${secrets_bucket_name}" \
    "${enable_kresd}" \
    "${enable_consul}" \
    "${enable_nomad}" \
    "${enable_cloudflared}" \
    "${enable_esm}" \
    "${enable_vault}"

  if [[ "${enable_service_discovery}" == "true" ]]; then
    write_service_discovery_configuration
  fi

  systemctl daemon-reload

  local services=()

  services+=("node-exporter.service")
  services+=("vector.service")
  services+=("amp-proxy.service")

  if [[ "${enable_service_discovery}" == "true" ]]; then
    services+=("vector-service-discovery.service")
  fi

  systemctl --no-block enable "${services[@]}"
  systemctl --no-block restart "${services[@]}"
}

run "$@"
