#!/usr/bin/env bash

set -e
set -u
set -o pipefail

umask 027

SCRIPT_NAME=
SCRIPT_NAME="$(basename "$0")"

declare -A OBSERVABILITY_TAGS

TELEMETRY_ENVIRONMENT_FILE_PATH="/etc/sysconfig/telemetry-environment"

function wrap {
 local strings="${1}"

 local length
 local cols
 local width

 length="$(echo -n "${strings}" | awk -F '|' '{print $1}' | awk '{ print length }' | sort -n | tail -1)"
 cols="$(tput cols)"

 if [[ $(( (cols - 4) / length )) -ge 2 ]]
 then
  if [[ $((cols - length - 4)) -ge 80 ]]
  then
    width=80
  else
    width=$((cols - length - 4))
  fi

   echo -e "${strings}" | \
    fold -s -w "${width}" | \
    sed -e "/--/! s|^| \||g" | \
    column -t -s '|' | \
    sed  's/^/  /'
 else
    local lines
    local line
    readarray -t lines <<< "${strings}"
    local option
    local description

    if [[ "${cols}" -ge 80 ]]
    then
      width="78"
    else
      width=$((cols - 2))
    fi

    for line in "${lines[@]}"; do
      option="${line%%|*}"
      description=${line#*|}

      echo "${option}"
      echo
      echo "${description}" | fold -s -w "${width}" |  sed  's/^/  /'
      echo
    done
 fi
}

function print_usage {
  echo
  echo "Usage: ${SCRIPT_NAME} [OPTIONS]"
  echo
  echo "This script is used to configure observability on a AWS EC2 server."
  echo
  echo "Options:"
  echo
  wrap "$(
    echo -e "--amp-workspace-id|Amazon Managed Service for Prometheus Workspace ID."
    echo -e "--cloudwatch-group-name|CloudWatch log group name."
    echo -e "--enable-consul|Collect consul metrics."
    echo -e "--enable-kresd|Collect knot resolver metrics."
    echo -e "--enable-nomad|Collect nomad metrics."
    echo -e "--scrape-interval|The interval between scrapes, in seconds."
    echo -e "--secrets-bucket-name|AWS S3 secrets bucket name."
    echo -e "--tag|Tag vector logs and metrics. Repeat this option for additional tags."
  )"
  echo
}

function log {
  local -r level="$1"
  local -r message="$2"
  local timestamp

  timestamp="$(date +"%Y-%m-%d %H:%M:%S")"

  >&2 echo -e "${timestamp} [${level}] [$SCRIPT_NAME] ${message}"
}

function log_info {
  local -r message="$1"
  log "INFO" "$message"
}

function log_warn {
  local -r message="$1"
  log "WARN" "$message"
}

function log_error {
  local -r message="$1"
  log "ERROR" "$message"
}

function assert_not_empty {
  local -r arg_name="$1"
  local -r arg_value="$2"

  if [[ -z "$arg_value" ]]; then
    log_error "The value for '$arg_name' cannot be empty"
    print_usage
    exit 1
  fi
}

function assert_is_installed {
  local -r name="$1"

  if [[ ! $(command -v "${name}") ]]; then
    log_error "The binary '$name' is required by this script but is not installed or in the system's PATH."
    exit 1
  fi
}

function parse_tag {
  local string="${1}"
  local -r regex="^([a-zA-Z_][a-zA-Z0-9_]*)=([a-zA-Z_:][a-zA-Z0-9_:]*)"
  local name
  local value

  if [[ "${string}" =~ ${regex} && "${#BASH_REMATCH[@]}" == "3" ]]
  then
    name="${BASH_REMATCH[1]}"
    value="${BASH_REMATCH[2]}"
    OBSERVABILITY_TAGS["${name}"]="${value}"
  else
    log_error "Unable to parse tag: ${string}"
  fi
}

function join {
  local d=${1-} f=${2-}

  if shift 2; then
    printf %s "$f" "${@/#/$d}"
  fi
}

function get_object_value {
  local -r secrets_bucket_name="$1"
  local -r source="$2"

  local -r key="${EC2_INSTANCE_REGION}/${source}"

  log_info "Downloading ${key}"

  aws s3 cp --quiet \
    "s3://${secrets_bucket_name}/${key}" /dev/stdout || exit 1
}

function write_vector_configuration {
  local -r secrets_bucket_name="${1}"
  local -r cloudwatch_group_name="${2}"
  local -r scrape_interval="${3}"
  local -r enable_kresd="${4}"
  local -r enable_consul="${5}"
  local -r enable_nomad="${6}"
  local -r enable_cloudflared="${7}"

  local -r vector_configuration_path="/etc/vector/vector.toml"
  local -r vector_telemetry_environment_path="/etc/systemd/system/vector.service.d/telemetry-environment.conf"

  local metrics_metadata_tags

  metrics_metadata_tags=$(
    for name in "${!OBSERVABILITY_TAGS[@]}"
    do
      echo ".tags.${name}=\"${OBSERVABILITY_TAGS[$name]:-false}\""
    done
  )

  local logs_metadata_tags

  logs_metadata_tags=$(
    for name in "${!OBSERVABILITY_TAGS[@]}"
    do
      echo ".${name}=\"${OBSERVABILITY_TAGS[$name]:-false}\""
    done
  )

  local consul_acl_token

  consul_acl_token="$(get_object_value "${secrets_bucket_name}" "telemetry/consul-acl-token-consul-telemetry")"

  local vector_configuration_kresd=""
  local vector_configuration_consul=""
  local vector_configuration_nomad=""
  local vector_configuration_cloudflared=""
  local vector_sources_list_array=("\"metrics-amp-proxy\"" "\"metrics-node-exporter\"" "\"metrics-vector\"")

  if [[ "${enable_consul}" == "true" ]]
  then
    vector_sources_list_array+=("\"metrics-consul\"")

    vector_configuration_consul=$(cat <<EOF

## CONSUL

[sources.metrics-not-tagged-consul]
type = "prometheus_scrape"
endpoints = ["http://127.0.0.1:8500/v1/agent/metrics?format=prometheus"]
scrape_interval_secs = ${scrape_interval}

[sources.metrics-not-tagged-consul.auth]
token = "${consul_acl_token}"
strategy = "bearer"

[transforms.metrics-consul]
type = "remap"
inputs = ["metrics-not-tagged-consul"]
source = '.tags.service = "consul"'

EOF
)
  fi

  if [[ "${enable_kresd}" == "true" ]]
  then
    vector_sources_list_array+=("\"metrics-kresd\"")

    vector_configuration_kresd=$(cat <<EOF

## KRESD

[sources.metrics-not-tagged-kresd]
type = "prometheus_scrape"
endpoints = ["http://127.0.0.1:8453/metrics"]
scrape_interval_secs = ${scrape_interval}

[transforms.metrics-kresd]
type = "remap"
inputs = ["metrics-not-tagged-kresd"]
source = '.tags.service = "kresd"'

EOF
)
  fi

  if [[ "${enable_nomad}" == "true" ]]
  then
    vector_sources_list_array+=("\"metrics-nomad\"")

    vector_configuration_nomad=$(cat <<EOF

## NOMAD

[sources.metrics-not-tagged-nomad]
type = "prometheus_scrape"
endpoints = ["https://127.0.0.1:4646/v1/metrics?format=prometheus"]
scrape_interval_secs = ${scrape_interval}

[transforms.metrics-nomad]
type = "remap"
inputs = ["metrics-not-tagged-nomad"]
source = '.tags.service = "nomad"'

EOF
)
  fi

  if [[ "${enable_cloudflared}" == "true" ]]
  then
    vector_sources_list_array+=("\"metrics-cloudflared\"")

    vector_configuration_cloudflared=$(cat <<EOF

## cloudflared

[sources.metrics-not-tagged-cloudflared]
type = "prometheus_scrape"
endpoints = ["http://127.0.0.1:9301/metrics"]
scrape_interval_secs = ${scrape_interval}

[transforms.metrics-cloudflared]
type = "remap"
inputs = ["metrics-not-tagged-cloudflared"]
source = '.tags.service = "cloudflared"'

EOF
)
  fi

  local vector_sources_list
  vector_sources_list="$(join ", " "${vector_sources_list_array[@]}")"

  local -r vector_configuration=$(cat <<EOF
healthchecks.require_healthy = false

# JOURNALD

[sources.logs-journald]
type = "journald"
current_boot_only = true

## NODE EXPORTER

[sources.metrics-not-tagged-node-exporter]
type = "prometheus_scrape"
endpoints = ["http://127.0.0.1:9100/metrics"]
scrape_interval_secs = ${scrape_interval}

[transforms.metrics-node-exporter]
type = "remap"
inputs = ["metrics-not-tagged-node-exporter"]
source = '.tags.service = "node-exporter"'

## VECTOR

[sources.metrics-not-tagged-vector]
type = "internal_metrics"
scrape_interval_secs = ${scrape_interval}

[transforms.metrics-vector]
type = "remap"
inputs = ["metrics-not-tagged-vector"]
source = '.tags.service = "vector"'

## AMP-PROXY

[sources.metrics-not-tagged-amp-proxy]
type = "prometheus_scrape"
endpoints = ["http://127.0.0.1:9901/stats/prometheus"]
scrape_interval_secs = ${scrape_interval}

[transforms.metrics-amp-proxy]
type = "remap"
inputs = ["metrics-not-tagged-amp-proxy"]
source = '.tags.service = "amp-proxy"'

${vector_configuration_kresd}
${vector_configuration_consul}
${vector_configuration_nomad}
${vector_configuration_cloudflared}

## ---

[transforms.metrics-metadata]
type = "remap"
source = '''
.tags.region = get_env_var!("EC2_INSTANCE_REGION")
.tags.instance_id = get_env_var!("EC2_INSTANCE_ID")
.tags.instance_type = get_env_var!("EC2_INSTANCE_TYPE")
.tags.availability_zone = get_env_var!("EC2_INSTANCE_AVAILABILITY_ZONE")
del(.tags.host)
${metrics_metadata_tags}
'''
inputs = [${vector_sources_list}]

[transforms.logs-metadata]
type = "remap"
source = '''
.region = get_env_var!("EC2_INSTANCE_REGION")
.instance_id = get_env_var!("EC2_INSTANCE_ID")
.instance_type = get_env_var!("EC2_INSTANCE_TYPE")
.availability_zone = get_env_var!("EC2_INSTANCE_AVAILABILITY_ZONE")
del(.host)
${logs_metadata_tags}
'''
inputs = [
  "logs-journald"
]

## ---

[sinks.metrics-amp-sink]
type = "prometheus_remote_write"
endpoint = "http://127.0.0.1:9201/api/v1/remote_write"
healthcheck = false
inputs = [
  "metrics-metadata"
]

[sinks.logs-cloudwatch-sink]
type = "aws_cloudwatch_logs"
create_missing_group = true
create_missing_stream = true
group_name = "${cloudwatch_group_name}"
compression = "gzip"
region = "${EC2_INSTANCE_REGION}"
encoding = "json"
stream_name = "{{ instance_id }}"
inputs = [
  "logs-metadata"
]

EOF
)

  log_info "Writing ${vector_configuration_path}"

  echo -e "${vector_configuration}" > "${vector_configuration_path}"

  chown vector:vector "${vector_configuration_path}"
  chmod 640 "${vector_configuration_path}"

  mkdir -p "$(dirname "${vector_telemetry_environment_path}")"
  chown root:root "$(dirname "${vector_telemetry_environment_path}")"
  chmod 755 "$(dirname "${vector_telemetry_environment_path}")"

  log_info "Writing ${vector_telemetry_environment_path}"

  local -r vector_telemetry_environment=$(cat <<EOF
[Unit]
After=consul-online.target
Wants=consul-online.target
After=nomad.service
Wants=nomad.service
After=kresd.target
Wants=kresd.target
After=node-exporter.service
Wants=node-exporter.service

[Service]
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
EOF
)

  echo -e "${vector_telemetry_environment}" > "${vector_telemetry_environment_path}"
  chown root:root "${vector_telemetry_environment_path}"
  chmod 644 "${vector_telemetry_environment_path}"
}

function write_telemetry_environment {
  local -r telemetry_environment_file_path="${TELEMETRY_ENVIRONMENT_FILE_PATH}"

  local aws_access_key_id
  local aws_secret_access_key

  aws_access_key_id="$(get_object_value "${secrets_bucket_name}" "telemetry/aws-access-key-id-telemetry")"
  aws_secret_access_key="$(get_object_value "${secrets_bucket_name}" "telemetry/aws-secret-access-key-telemetry")"

  local -r telemetry_environment=$(cat <<EOF
AWS_ACCESS_KEY_ID=${aws_access_key_id}
AWS_SECRET_ACCESS_KEY=${aws_secret_access_key}
EOF
)

  log_info "Writing ${telemetry_environment_file_path}"

  echo -e "${telemetry_environment}" > "${telemetry_environment_file_path}"
  chown root:root  "${telemetry_environment_file_path}"
  chmod 640 "${telemetry_environment_file_path}"

  setfacl -m u:vector:r "${telemetry_environment_file_path}"
  setfacl -m u:amp-proxy:r "${telemetry_environment_file_path}"
}

function write_amp_proxy_configuration {
  local -r secrets_bucket_name="${1}"
  local -r workspace_id="${2}"
  local -r region="${EC2_INSTANCE_REGION}"

  local -r amp_proxy_configuration_path="/opt/amp-proxy/config/default.yml"
  local -r amp_proxy_service_configuration_path="/etc/systemd/system/amp-proxy.service"

  local -r amp_proxy_configuration=$(cat <<EOF
admin:
  address:
    socket_address: { address: 127.0.0.1, port_value: 9901 }

static_resources:
  listeners:
    - address:
        socket_address:
          protocol: "TCP"
          address: "127.0.0.1"
          port_value: 9201
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                codec_type: AUTO
                stat_prefix: amp-proxy
                strip_any_host_port: true
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: amp-proxy
                      domains: ['*']
                      routes:
                        - name: amp-proxy
                          match:
                            prefix: /
                          route:
                            cluster: amp-proxy
                http_filters:
                  - name: envoy.filters.http.lua
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua
                      inline_code: |
                        -- Called on the request path.
                        function envoy_on_request(request_handle)
                          local path = request_handle:headers():get(":path")
                          request_handle:headers():replace(":path", "/workspaces/${workspace_id}" .. path)
                        end
                        -- Called on the response path.
                        function envoy_on_response(response_handle)
                        end
                  - name: envoy.filters.http.aws_request_signing
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.aws_request_signing.v3.AwsRequestSigning
                      service_name: aps
                      region: ${region}
                      host_rewrite: aps-workspaces.${region}.amazonaws.com
                  - name: envoy.filters.http.router
                    typed_config: {}
  clusters:
    - name: amp-proxy
      connect_timeout: 0.25s
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      transport_socket:
        name: envoy.transport_sockets.tls
      load_assignment:
        cluster_name: amp-proxy
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: aps-workspaces.${region}.amazonaws.com
                      port_value: 443
EOF
)

  local -r amp_proxy_service_configuration=$(cat <<EOF
[Unit]
Description=Amazon Managed Service for Prometheus Signing Proxy
After=network-online.target
Wants=network-online.target

[Service]
User=amp-proxy
Group=amp-proxy
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
ExecStart=/usr/bin/envoy --use-dynamic-base-id --disable-hot-restart --log-level error --config-path "${amp_proxy_configuration_path}"
KillMode=mixed
LimitNOFILE=640000
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
WantedBy=vector.service

EOF
)

  log_info "Writing ${amp_proxy_configuration_path}"
  log_info "Writing ${amp_proxy_service_configuration_path}"

  echo -e "$amp_proxy_configuration" > "$amp_proxy_configuration_path"
  chown amp-proxy:amp-proxy "${amp_proxy_configuration_path}"
  chmod 644 "${amp_proxy_configuration_path}"

  echo -e "$amp_proxy_service_configuration" > "$amp_proxy_service_configuration_path"
  chown root:root "${amp_proxy_service_configuration_path}"
  chmod 644 "${amp_proxy_service_configuration_path}"
}

function configure_node_exporter {
  local node_exporter_options_path="/opt/node-exporter/config/options"

  local node_exporter_options_array=(
    '--collector.conntrack'
    '--collector.cpu'
    '--collector.disable-defaults'
    '--collector.diskstats'
    '--collector.diskstats.ignored-devices="^(dm-|ram|loop|fd|(h|s|v|xv)d[a-z]|nvme[0-9]+n[0-9]+p)[0-9]+\$"'
    '--collector.entropy'
    '--collector.filesystem'
    '--collector.filesystem.fs-types-exclude="^(tmpfs|systemd-1|efivarfs|autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)\$"'
    '--collector.filesystem.mount-points-exclude="^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)(\$|/)"'
    '--collector.loadavg'
    '--collector.meminfo'
    '--collector.netclass'
    '--collector.netclass.ignored-devices="^(nomad|docker.+|lo|dummy.+|veth.+)\$"'
    '--collector.netdev'
    '--collector.netdev.device-exclude="^(nomad|docker.+|lo|dummy.+|veth.+)\$"'
    '--collector.pressure'
    '--collector.processes'
    '--collector.schedstat'
    '--collector.stat'
    '--collector.systemd'
    '--collector.systemd.unit-include="(nomad.service|consul.service,amp-proxy.service|vector.service|kresd@.+|consul-terraform-sync.service|sshd.service)"'
    '--collector.timex'
    '--collector.vmstat'
    '--web.listen-address="127.0.0.1:9100"'
  )

  local node_exporter_options
  node_exporter_options="OPTIONS=$(join " " "${node_exporter_options_array[@]}")"

  echo -e "$node_exporter_options" > "${node_exporter_options_path}"
  chown node-exporter:node-exporter "${node_exporter_options_path}"
  chmod 640 "${node_exporter_options_path}"
}

function run {
  if [[ ! -f "/etc/sysconfig/ec2-environment" ]]
  then
    print_usage

    log_error "/etc/sysconfig/ec2-environment: No such file"

    exit 1
  fi

  set -o allexport
  source "/etc/sysconfig/ec2-environment"
  set +o allexport

  local secrets_bucket_name=""
  local cloudwatch_group_name=""
  local amp_workspace_id=""
  local scrape_interval="60"
  local enable_kresd="false"
  local enable_consul="false"
  local enable_nomad="false"
  local enable_cloudflared="false"

  while [[ $# -gt 0 ]]; do
    local key="$1"

    case "$key" in
      --scrape-interval)
        assert_not_empty "$key" "$2"
        scrape_interval="$2"
        shift
        ;;
      --secrets-bucket-name)
        assert_not_empty "$key" "$2"
        secrets_bucket_name="$2"
        shift
        ;;
      --amp-workspace-id)
        assert_not_empty "$key" "$2"
        amp_workspace_id="$2"
        shift
        ;;
      --cloudwatch-group-name)
        assert_not_empty "$key" "$2"
        cloudwatch_group_name="$2"
        shift
        ;;
      --tag)
        assert_not_empty "$key" "$2"
        parse_tag "${2}"
        shift
        ;;
      --enable-kresd)
        enable_kresd=true
        ;;
      --enable-consul)
        enable_consul=true
        ;;
      --enable-nomad)
        enable_nomad=true
        ;;
      --enable-cloudflared)
        enable_cloudflared=true
        ;;
      --help)
        print_usage
        exit
        ;;
      *)
        log_error "Unrecognized argument: $key"
        print_usage
        exit 1
        ;;
    esac

    shift
  done

  assert_not_empty "--secrets-bucket-name" "${secrets_bucket_name}"
  assert_not_empty "--cloudwatch-group-name" "${cloudwatch_group_name}"
  assert_not_empty "--amp-workspace-id" "${amp_workspace_id}"

  if ! [[ "${scrape_interval}" =~ ^[0-9]+$ ]]
  then
    log_error "--scrape-interval must be a number."
    print_usage
    exit 1
  fi

  assert_is_installed "systemctl"
  assert_is_installed "jq"
  assert_is_installed "awk"

  configure_node_exporter
  write_telemetry_environment
  write_amp_proxy_configuration "${secrets_bucket_name}" "${amp_workspace_id}"

  write_vector_configuration "${secrets_bucket_name}" "${cloudwatch_group_name}" "${scrape_interval}" "${enable_kresd}" "${enable_consul}" "${enable_nomad}" "${enable_cloudflared}"

  systemctl daemon-reload
  systemctl enable node-exporter vector amp-proxy
  systemctl restart node-exporter amp-proxy vector
}

run "$@"
