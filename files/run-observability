#!/usr/bin/env bash

set -e
set -u
set -o pipefail

umask 027

SCRIPT_NAME=
SCRIPT_NAME="$(basename "$0")"

declare -A OBSERVABILITY_TAGS

TELEMETRY_ENVIRONMENT_FILE_PATH="/etc/sysconfig/telemetry-environment"

function wrap() {
  local strings="${1}"

  local length
  local cols
  local width

  length="$(echo -n "${strings}" | awk -F '|' '{print $1}' | awk '{ print length }' | sort -n | tail -1)"
  cols="$(tput cols)"

  if [[ $(((cols - 4) / length)) -ge 2 ]]; then
    if [[ $((cols - length - 4)) -ge 80 ]]; then
      width=80
    else
      width=$((cols - length - 4))
    fi

    echo -e "${strings}" \
      | fold -s -w "${width}" \
      | sed -e "/--/! s|^| \||g" \
      | column -t -s '|' \
      | sed 's/^/  /'
  else
    local lines
    local line
    readarray -t lines <<< "${strings}"
    local option
    local description

    if [[ "${cols}" -ge 80 ]]; then
      width="78"
    else
      width=$((cols - 2))
    fi

    for line in "${lines[@]}"; do
      option="${line%%|*}"
      description=${line#*|}

      echo "${option}"
      echo
      echo "${description}" | fold -s -w "${width}" | sed 's/^/  /'
      echo
    done
  fi
}

function print_usage() {
  echo
  echo "Usage: ${SCRIPT_NAME} [OPTIONS]"
  echo
  echo "This script is used to configure observability on a AWS EC2 server."
  echo
  echo "Options:"
  echo
  wrap "$(
    echo -e "--amp-workspace-id|Amazon Managed Service for Prometheus Workspace ID."
    echo -e "--cloudwatch-group-name|CloudWatch log group name."
    echo -e "--enable-consul|Collect consul metrics."
    echo -e "--enable-service-discovery|Discover scrape targets running on this node."
    echo -e "--enable-kresd|Collect knot resolver metrics."
    echo -e "--enable-nomad|Collect nomad metrics."
    echo -e "--scrape-interval|The interval between scrapes, in seconds."
    echo -e "--secrets-bucket-name|AWS S3 secrets bucket name."
    echo -e "--tag|Tag vector logs and metrics. Repeat this option for additional tags."
  )"
  echo
}

function log() {
  local -r level="$1"
  local -r message="$2"
  local timestamp

  timestamp="$(date +"%Y-%m-%d %H:%M:%S")"

  echo >&2 -e "${timestamp} [${level}] [$SCRIPT_NAME] ${message}"
}

function log_info() {
  local -r message="$1"
  log "INFO" "$message"
}

function log_warn() {
  local -r message="$1"
  log "WARN" "$message"
}

function log_error() {
  local -r message="$1"
  log "ERROR" "$message"
}

function assert_not_empty() {
  local -r arg_name="$1"
  local -r arg_value="$2"

  if [[ -z "$arg_value" ]]; then
    log_error "The value for '$arg_name' cannot be empty"
    print_usage
    exit 1
  fi
}

function assert_is_installed() {
  local -r name="$1"

  if [[ ! $(command -v "${name}") ]]; then
    log_error "The binary '$name' is required by this script but is not installed or in the system's PATH."
    exit 1
  fi
}

function parse_tag() {
  local string="${1}"
  local -r regex="^([a-zA-Z_][a-zA-Z0-9_]*)=([a-zA-Z_:][a-zA-Z0-9_:]*)"
  local name
  local value

  if [[ "${string}" =~ ${regex} && "${#BASH_REMATCH[@]}" == "3" ]]; then
    name="${BASH_REMATCH[1]}"
    value="${BASH_REMATCH[2]}"
    OBSERVABILITY_TAGS["${name}"]="${value}"
  else
    log_error "Unable to parse tag: ${string}"
  fi
}

function join() {
  local d=${1-} f=${2-}

  if shift 2; then
    printf %s "$f" "${@/#/$d}"
  fi
}

function get_object_value() {
  local -r secrets_bucket_name="$1"
  local -r source="$2"

  local -r key="${EC2_INSTANCE_REGION}/${source}"

  log_info "Downloading ${key}"

  aws s3 cp --quiet \
    "s3://${secrets_bucket_name}/${key}" /dev/stdout || exit 1
}

function write_vector_configuration() {
  local -r enable_kresd="${1}"
  local -r enable_consul="${2}"
  local -r enable_nomad="${3}"
  local -r enable_cloudflared="${4}"

  local -r vector_configuration_path="/etc/vector/vector.toml"
  local -r vector_telemetry_environment_path="/etc/systemd/system/vector.service.d/telemetry-environment.conf"

  local metrics_metadata_tags

  metrics_metadata_tags=$(
    for name in "${!OBSERVABILITY_TAGS[@]}"; do
      echo ".tags.${name}=\"${OBSERVABILITY_TAGS[$name]:-false}\""
    done
  )

  local logs_metadata_tags

  logs_metadata_tags=$(
    for name in "${!OBSERVABILITY_TAGS[@]}"; do
      echo ".${name}=\"${OBSERVABILITY_TAGS[$name]:-false}\""
    done
  )

  local vector_configuration_kresd=""
  local vector_configuration_consul=""
  local vector_configuration_nomad=""
  local vector_configuration_cloudflared=""
  local vector_sources_list_array=("\"metrics-amp-proxy\"" "\"metrics-node-exporter\"" "\"metrics-vector\"")

  if [[ "${enable_consul}" == "true" ]]; then
    vector_sources_list_array+=("\"metrics-consul*\"")

    vector_configuration_consul=$(
      cat << EOF

## CONSUL

[sources.intermediate-metrics-consul]
type = "prometheus_scrape"
endpoints = ["http://[::1]:8500/v1/agent/metrics?format=prometheus"]
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[sources.intermediate-metrics-consul.auth]
token = "\${CONSUL_HTTP_TOKEN}"
strategy = "bearer"

[transforms.metrics-consul]
type = "remap"
inputs = ["intermediate-metrics-consul"]
source = '.tags.service = "consul"'

EOF
    )
  fi

  if [[ "${enable_kresd}" == "true" ]]; then
    vector_sources_list_array+=("\"metrics-kresd\"")

    vector_configuration_kresd=$(
      cat << EOF

## KRESD

[sources.intermediate-metrics-kresd]
type = "prometheus_scrape"
endpoints = ["http://[::1]:8453/metrics"]
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-kresd]
type = "remap"
inputs = ["intermediate-metrics-kresd"]
source = '.tags.service = "kresd"'

EOF
    )
  fi

  if [[ "${enable_nomad}" == "true" ]]; then
    vector_sources_list_array+=("\"metrics-nomad\"")

    vector_configuration_nomad=$(
      cat << EOF

## NOMAD

[sources.intermediate-metrics-nomad]
type = "prometheus_scrape"
# TODO: vector fails tls verification with [::1]
endpoints = ["https://localhost:4646/v1/metrics?format=prometheus"]
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-nomad]
type = "remap"
inputs = ["intermediate-metrics-nomad"]
source = '.tags.service = "nomad"'

EOF
    )
  fi

  if [[ "${enable_cloudflared}" == "true" ]]; then
    vector_sources_list_array+=("\"metrics-cloudflared\"")

    vector_configuration_cloudflared=$(
      cat << EOF

## cloudflared

[sources.intermediate-metrics-cloudflared]
type = "prometheus_scrape"
endpoints = ["http://[::1]:9301/metrics"]
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-cloudflared]
type = "remap"
inputs = ["intermediate-metrics-cloudflared"]
source = '.tags.service = "cloudflared"'

EOF
    )
  fi

  local vector_sources_list
  vector_sources_list="$(join ", " "${vector_sources_list_array[@]}")"

  local -r vector_configuration=$(
    cat << EOF
[healthchecks]
enabled = true
require_healthy = false

[api]
enabled = false
address = "127.0.0.1:8686"

# JOURNALD

[sources.logs-journald]
type = "journald"
current_boot_only = true

## NODE EXPORTER

[sources.intermediate-metrics-node-exporter]
type = "prometheus_scrape"
endpoints = ["http://[::1]:9100/metrics"]
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-node-exporter]
type = "remap"
inputs = ["intermediate-metrics-node-exporter"]
source = '.tags.service = "node-exporter"'

## VECTOR

[sources.intermediate-metrics-vector]
type = "internal_metrics"
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-vector]
type = "remap"
inputs = ["intermediate-metrics-vector"]
source = '.tags.service = "vector"'

## AMP-PROXY

[sources.intermediate-metrics-amp-proxy]
type = "prometheus_scrape"
endpoints = ["http://[::1]:9901/stats/prometheus"]
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-amp-proxy]
type = "remap"
inputs = ["intermediate-metrics-amp-proxy"]
source = '.tags.service = "amp-proxy"'

${vector_configuration_kresd}
${vector_configuration_consul}
${vector_configuration_nomad}
${vector_configuration_cloudflared}

## ---

[transforms.intermediate-metrics-enrich]
type = "remap"
source = '''
.tags.region = get_env_var!("EC2_INSTANCE_REGION")
.tags.instance_id = get_env_var!("EC2_INSTANCE_ID")
.tags.instance_type = get_env_var!("EC2_INSTANCE_TYPE")
.tags.availability_zone = get_env_var!("EC2_INSTANCE_AVAILABILITY_ZONE")
del(.tags.host)
${metrics_metadata_tags}
'''
inputs = [${vector_sources_list}]

[transforms.intermediate-logs-enrich]
type = "remap"
source = '''
.region = get_env_var!("EC2_INSTANCE_REGION")
.instance_id = get_env_var!("EC2_INSTANCE_ID")
.instance_type = get_env_var!("EC2_INSTANCE_TYPE")
.availability_zone = get_env_var!("EC2_INSTANCE_AVAILABILITY_ZONE")
del(.host)
${logs_metadata_tags}
'''
inputs = [
  "logs-journald"
]

## ---

[transforms.intermediate-metrics-filter]
type = "filter"
inputs = [
  "intermediate-metrics-enrich"
]
condition.type = "vrl"
condition.source = '''
  if exists(.name) {
    if (starts_with(.name, "envoy_") ?? false) {
      match_any(.name, [
        r'^envoy_cluster_upstream_cx',
        r'^envoy_cluster_upstream_rq',
        r'^envoy_cluster_upstream_rq_time_bucket',
        r'^envoy_cluster_upstream_rq_total',
        r'^envoy_cluster_upstream_rq_xx',
        r'^envoy_http_downstream_cx_active',
        r'^envoy_http_downstream_cx_rx_bytes_total',
        r'^envoy_http_downstream_cx_total',
        r'^envoy_http_downstream_cx_tx_bytes_total',
        r'^envoy_http_downstream_rq',
        r'^envoy_http_downstream_rq_total',
        r'^envoy_http_downstream_rq_xx',
        r'^envoy_listener_http_downstream_rq_xx',
        r'^envoy_tcp_downstream_cx',
        r'^envoy_tcp_downstream_cx_rx_bytes_total',
        r'^envoy_tcp_downstream_cx_tx_bytes_total'
      ]) ?? false
    } else if (starts_with(.name, "go_") ?? false) {
      match_any(.name, [
        r'^go_gc_duration_seconds_sum',
        r'^go_go_goroutines',
        r'^go_memstats_alloc_bytes',
        r'^go_memstats_alloc_bytes_total',
        r'^go_memstats_heap_inuse_bytes',
        r'^go_memstats_stack_inuse_bytes'
      ]) ?? false
    } else if (starts_with(.name, "node_") ?? false) {
      match_any(.name, [
        r'^node_context_switches_total',
        r'^node_cpu_seconds_total',
        r'^node_disk_discard_time_seconds_total',
        r'^node_disk_discards_completed_total',
        r'^node_disk_discards_merged_total',
        r'^node_disk_io_now',
        r'^node_disk_io_time_seconds_total',
        r'^node_disk_io_time_weighted_seconds_total',
        r'^node_disk_read_bytes_total',
        r'^node_disk_read_time_seconds_total',
        r'^node_disk_reads_completed_total',
        r'^node_disk_reads_merged_total',
        r'^node_disk_write_time_seconds_total',
        r'^node_disk_writes_completed_total',
        r'^node_disk_writes_merged_total',
        r'^node_disk_written_bytes_total',
        r'^node_entropy_available_bits',
        r'^node_filesystem_avail_bytes',
        r'^node_filesystem_device_error',
        r'^node_filesystem_free_bytes',
        r'^node_filesystem_readonly',
        r'^node_filesystem_size_bytes',
        r'^node_forks_total',
        r'^node_intr_total',
        r'^node_load1',
        r'^node_load15',
        r'^node_load5',
        r'^node_memory_Buffers_bytes',
        r'^node_memory_Cached_bytes',
        r'^node_memory_HardwareCorrupted_bytes',
        r'^node_memory_MemFree_bytes',
        r'^node_memory_MemTotal_bytes',
        r'^node_memory_PageTables_bytes',
        r'^node_memory_SReclaimable_bytes',
        r'^node_memory_Slab_bytes',
        r'^node_memory_SwapCached_bytes',
        r'^node_memory_SwapFree_bytes',
        r'^node_memory_SwapTotal_bytes',
        r'^node_network_receive_bytes_total',
        r'^node_network_receive_drop_total',
        r'^node_network_receive_errs_total',
        r'^node_network_receive_packets_total',
        r'^node_network_transmit_bytes_total',
        r'^node_network_transmit_drop_total',
        r'^node_network_transmit_errs_total',
        r'^node_network_transmit_packets_total',
        r'^node_processes_max_threads',
        r'^node_processes_state',
        r'^node_processes_threads',
        r'^node_procs_blocked',
        r'^node_procs_running',
        r'^node_schedstat_running_seconds_total',
        r'^node_schedstat_timeslices_total',
        r'^node_schedstat_waiting_seconds_total',
        r'^node_scrape_collector_duration_seconds',
        r'^node_systemd_units',
        r'^node_timex_estimated_error_seconds',
        r'^node_timex_maxerror_seconds',
        r'^node_timex_offset_seconds'
      ]) ?? false
    } else {
      !(match_any(.name, [
        r'^build_info'
      ]) ?? true)
    }
  } else {
    false
  }
'''

[sinks.metrics-amp-sink]
type = "prometheus_remote_write"
endpoint = "http://[::1]:9201/api/v1/remote_write"
healthcheck = false
inputs = [
  "intermediate-metrics-filter"
]

[sinks.logs-cloudwatch-sink]
type = "aws_cloudwatch_logs"
create_missing_group = true
create_missing_stream = true
group_name = "\${AWS_CLOUDWATCH_GROUP_NAME}"
compression = "gzip"
region = "${EC2_INSTANCE_REGION}"
encoding = "json"
stream_name = "{{ instance_id }}"
inputs = [
  "intermediate-logs-enrich"
]

EOF
  )

  log_info "Writing ${vector_configuration_path}"

  echo -e "${vector_configuration}" > "${vector_configuration_path}"

  chown vector:vector "${vector_configuration_path}"
  chmod 640 "${vector_configuration_path}"

  mkdir -p "$(dirname "${vector_telemetry_environment_path}")"
  chown root:root "$(dirname "${vector_telemetry_environment_path}")"
  chmod 755 "$(dirname "${vector_telemetry_environment_path}")"

  log_info "Writing ${vector_telemetry_environment_path}"

  local -r vector_telemetry_environment=$(
    cat << EOF
[Unit]
After=consul-online.target
Wants=consul-online.target
After=nomad.service
Wants=nomad.service
After=kresd.target
Wants=kresd.target
After=node-exporter.service
Wants=node-exporter.service

[Service]
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
EOF
  )

  echo -e "${vector_telemetry_environment}" > "${vector_telemetry_environment_path}"
  chown root:root "${vector_telemetry_environment_path}"
  chmod 644 "${vector_telemetry_environment_path}"
}

function write_telemetry_environment() {
  local -r secrets_bucket_name="${1}"
  local -r scrape_interval="${2}"
  local -r cloudwatch_group_name="${3}"
  local -r telemetry_environment_file_path="${TELEMETRY_ENVIRONMENT_FILE_PATH}"

  local aws_access_key_id
  local aws_secret_access_key

  aws_access_key_id="$(get_object_value "${secrets_bucket_name}" "telemetry/aws-access-key-id-telemetry")"
  aws_secret_access_key="$(get_object_value "${secrets_bucket_name}" "telemetry/aws-secret-access-key-telemetry")"

  local consul_http_token

  consul_http_token="$(get_object_value "${secrets_bucket_name}" "telemetry/consul-acl-token-consul-telemetry")"

  local -r telemetry_environment=$(
    cat << EOF
AWS_ACCESS_KEY_ID=${aws_access_key_id}
AWS_SECRET_ACCESS_KEY=${aws_secret_access_key}
AWS_CLOUDWATCH_GROUP_NAME=${cloudwatch_group_name}
VECTOR_SCRAPE_INTERVAL=${scrape_interval}
CONSUL_HTTP_TOKEN=${consul_http_token}
EOF
  )

  log_info "Writing ${telemetry_environment_file_path}"

  echo -e "${telemetry_environment}" > "${telemetry_environment_file_path}"
  chown root:root "${telemetry_environment_file_path}"
  chmod 640 "${telemetry_environment_file_path}"

  setfacl -m u:vector:r "${telemetry_environment_file_path}"
  setfacl -m u:amp-proxy:r "${telemetry_environment_file_path}"
}

function write_amp_proxy_configuration() {
  local -r workspace_id="${1}"
  local -r region="${EC2_INSTANCE_REGION}"

  local -r amp_proxy_configuration_path="/opt/amp-proxy/config/default.yml"
  local -r amp_proxy_service_configuration_path="/etc/systemd/system/amp-proxy.service"

  local -r amp_proxy_configuration=$(
    cat << EOF
admin:
  address:
    socket_address: { address: "::1", port_value: 9901 }

static_resources:
  listeners:
    - address:
        socket_address:
          protocol: "TCP"
          address: "::1"
          port_value: 9201
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                codec_type: AUTO
                stat_prefix: amp-proxy
                strip_any_host_port: true
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: amp-proxy
                      domains: ['*']
                      routes:
                        - name: amp-proxy
                          match:
                            prefix: /
                          route:
                            cluster: amp-proxy
                http_filters:
                  - name: envoy.filters.http.lua
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.lua.v3.Lua
                      inline_code: |
                        -- Called on the request path.
                        function envoy_on_request(request_handle)
                          local path = request_handle:headers():get(":path")
                          request_handle:headers():replace(":path", "/workspaces/${workspace_id}" .. path)
                        end
                        -- Called on the response path.
                        function envoy_on_response(response_handle)
                        end
                  - name: envoy.filters.http.aws_request_signing
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.aws_request_signing.v3.AwsRequestSigning
                      service_name: aps
                      region: ${region}
                      host_rewrite: aps-workspaces.${region}.amazonaws.com
                      match_excluded_headers:
                        - prefix: x-envoy
                        - prefix: x-forwarded
                        - prefix: cf-
                        - prefix: sec-
                        - exact: cdn-loop
                        - exact: x-amzn-trace-id

                  - name: envoy.filters.http.router
                    typed_config: {}
  clusters:
    - name: amp-proxy
      connect_timeout: 0.25s
      type: LOGICAL_DNS
      lb_policy: ROUND_ROBIN
      transport_socket:
        name: envoy.transport_sockets.tls
      load_assignment:
        cluster_name: amp-proxy
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: aps-workspaces.${region}.amazonaws.com
                      port_value: 443
EOF
  )

  local -r amp_proxy_service_configuration=$(
    cat << EOF
[Unit]
Description=Amazon Managed Service for Prometheus Signing Proxy
After=network-online.target
Wants=network-online.target

[Service]
User=amp-proxy
Group=amp-proxy
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
ExecStart=/usr/bin/envoy --use-dynamic-base-id --disable-hot-restart --log-level error --config-path "${amp_proxy_configuration_path}"
KillMode=mixed
LimitNOFILE=640000
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
WantedBy=vector.service

EOF
  )

  log_info "Writing ${amp_proxy_configuration_path}"
  log_info "Writing ${amp_proxy_service_configuration_path}"

  echo -e "$amp_proxy_configuration" > "$amp_proxy_configuration_path"
  chown amp-proxy:amp-proxy "${amp_proxy_configuration_path}"
  chmod 644 "${amp_proxy_configuration_path}"

  echo -e "$amp_proxy_service_configuration" > "$amp_proxy_service_configuration_path"
  chown root:root "${amp_proxy_service_configuration_path}"
  chmod 644 "${amp_proxy_service_configuration_path}"
}

function write_service_discovery_configuration() {
  local -r vector_service_discovery_service_path="/etc/systemd/system/vector-service-discovery.service"
  local -r vector_service_discovery_template_path="/etc/vector/service-disccovery.ctmpl"
  local -r vector_service_discovery_configuration_path="/etc/vector/service-disccovery.toml"

  local -r vector_service_discovery_service=$(
    cat << EOF
[Unit]
Description=Vector Service Discovery
After=network-online.target
Wants=network-online.target
After=vector.service
Wants=vector.service

[Service]
User=vector
Group=vector
EnvironmentFile=${TELEMETRY_ENVIRONMENT_FILE_PATH}
ExecStart=consul-template -log-level=err -reload-signal=SIGHUP -kill-signal=SIGINT -consul-retry -consul-retry-attempts=0 -consul-retry-backoff=250ms -consul-retry-max-backoff=0 -template="${vector_service_discovery_template_path}:${vector_service_discovery_configuration_path}"
ExecReload=/bin/kill -HUP \$MAINPID
KillSignal=SIGINT
LimitNOFILE=640000
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target

EOF
  )

  local -r vector_service_discovery_template=$(
    cat << EOF
{{- with node -}}
{{- range .Services -}}
{{- if and (index .Meta "prometheus_endpoints") (.Service | regexMatch "-sidecar-proxy" | not) -}}
{{- scratch.MapSet "vars" .Service ("[]" | parseJSON) -}}
{{- end -}}
{{- end -}}
{{- end -}}

{{- with node -}}
{{- range .Services -}}
{{- if and (index .Meta "prometheus_endpoints") (.Service | regexMatch "-sidecar-proxy" | not) -}}
{{- \$value :=  sprig_uniq (sprig_concat ((index (scratch.Get "vars") .Service)) (.Meta.prometheus_endpoints | parseJSON)) -}}
{{- scratch.MapSet "vars" .Service \$value -}}
{{- end -}}
{{- end -}}
{{- end -}}

{{- range sprig_keys (scratch.Get "vars") }}
# {{ . }}

[sources.intermediate-metrics-consul-{{ sprig_snakecase . }}]
type = "prometheus_scrape"
endpoints = {{ index (scratch.Get "vars") . | sprig_uniq | toJSON }}
scrape_interval_secs = \${VECTOR_SCRAPE_INTERVAL:-60}

[transforms.metrics-consul-{{ sprig_snakecase . }}]
type = "remap"
inputs = ["intermediate-metrics-consul-{{ sprig_snakecase . }}"]
source = '.tags.service = "{{ . }}"'
{{- end }}

EOF
  )

  echo -e "$vector_service_discovery_service" > "$vector_service_discovery_service_path"
  chown root:root "${vector_service_discovery_service_path}"
  chmod 644 "${vector_service_discovery_service_path}"

  echo -e "$vector_service_discovery_template" > "$vector_service_discovery_template_path"
  chown vector:vector "${vector_service_discovery_template_path}"
  chmod 640 "${vector_service_discovery_template_path}"
}

function configure_node_exporter() {
  local node_exporter_options_path="/opt/node-exporter/config/options"

  # '--collector.conntrack'

  local node_exporter_options_array=(
    '--collector.cpu'
    '--collector.disable-defaults'
    '--collector.diskstats'
    '--collector.diskstats.ignored-devices="^(dm-|ram|loop|fd|(h|s|v|xv)d[a-z]|nvme[0-9]+n[0-9]+p)[0-9]+\$"'
    '--collector.entropy'
    '--collector.filesystem'
    '--collector.filesystem.fs-types-exclude="^(tmpfs|systemd-1|efivarfs|autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)\$"'
    '--collector.filesystem.mount-points-exclude="^/(dev|proc|run/credentials/.+|sys|var/lib/docker/.+)(\$|/)"'
    '--collector.loadavg'
    '--collector.meminfo'
    '--collector.netclass'
    '--collector.netclass.ignored-devices="^(nomad|docker.+|lo|dummy.+|veth.+)\$"'
    '--collector.netdev'
    '--collector.netdev.device-exclude="^(nomad|docker.+|lo|dummy.+|veth.+)\$"'
    '--collector.pressure'
    '--collector.processes'
    '--collector.schedstat'
    '--collector.stat'
    '--collector.systemd'
    '--collector.systemd.unit-include="(nomad.service|consul.service|amp-proxy.service|vector.service|kresd@.+|consul-terraform-sync.service|sshd.service|vector-service-discovery.service|ferm.service|ec2-environment.service|storage-setup.service|docker.service|consul-online.service)"'
    '--collector.timex'
    '--collector.vmstat'
    '--web.listen-address="[::1]:9100"'
  )

  local node_exporter_options
  node_exporter_options="OPTIONS=$(join " " "${node_exporter_options_array[@]}")"

  echo -e "$node_exporter_options" > "${node_exporter_options_path}"
  chown node-exporter:node-exporter "${node_exporter_options_path}"
  chmod 640 "${node_exporter_options_path}"
}

function run() {
  if [[ ! -f "/etc/sysconfig/ec2-environment" ]]; then
    print_usage

    log_error "/etc/sysconfig/ec2-environment: No such file"

    exit 1
  fi

  set -o allexport
  source "/etc/sysconfig/ec2-environment"
  set +o allexport

  local secrets_bucket_name=""
  local cloudwatch_group_name=""
  local amp_workspace_id=""
  local scrape_interval="60"
  local enable_kresd="false"
  local enable_consul="false"
  local enable_nomad="false"
  local enable_cloudflared="false"
  local enable_service_discovery="false"

  while [[ $# -gt 0 ]]; do
    local key="$1"

    case "$key" in
      --scrape-interval)
        assert_not_empty "$key" "$2"
        scrape_interval="$2"
        shift
        ;;
      --secrets-bucket-name)
        assert_not_empty "$key" "$2"
        secrets_bucket_name="$2"
        shift
        ;;
      --amp-workspace-id)
        assert_not_empty "$key" "$2"
        amp_workspace_id="$2"
        shift
        ;;
      --cloudwatch-group-name)
        assert_not_empty "$key" "$2"
        cloudwatch_group_name="$2"
        shift
        ;;
      --tag)
        assert_not_empty "$key" "$2"
        parse_tag "${2}"
        shift
        ;;
      --enable-kresd)
        enable_kresd=true
        ;;
      --enable-consul)
        enable_consul=true
        ;;
      --enable-nomad)
        enable_nomad=true
        ;;
      --enable-cloudflared)
        enable_cloudflared=true
        ;;
      --enable-service-discovery)
        enable_service_discovery=true
        ;;
      --help)
        print_usage
        exit
        ;;
      *)
        log_error "Unrecognized argument: $key"
        print_usage
        exit 1
        ;;
    esac

    shift
  done

  assert_not_empty "--secrets-bucket-name" "${secrets_bucket_name}"
  assert_not_empty "--cloudwatch-group-name" "${cloudwatch_group_name}"
  assert_not_empty "--amp-workspace-id" "${amp_workspace_id}"

  if ! [[ "${scrape_interval}" =~ ^[0-9]+$ ]]; then
    log_error "--scrape-interval must be a number."
    print_usage
    exit 1
  fi

  assert_is_installed "systemctl"
  assert_is_installed "jq"
  assert_is_installed "awk"

  if [[ "${enable_service_discovery}" == "true" ]]
  then
    assert_is_installed "consul-template"
  fi

  configure_node_exporter

  write_telemetry_environment \
    "${secrets_bucket_name}" \
    "${scrape_interval}" \
    "${cloudwatch_group_name}"

  write_amp_proxy_configuration \
    "${amp_workspace_id}"

  write_vector_configuration \
    "${enable_kresd}" \
    "${enable_consul}" \
    "${enable_nomad}" \
    "${enable_cloudflared}"

  if [[ "${enable_service_discovery}" == "true" ]]
  then
    write_service_discovery_configuration
  fi

  systemctl daemon-reload
  systemctl enable node-exporter vector amp-proxy
  systemctl restart node-exporter amp-proxy vector

  if [[ "${enable_service_discovery}" == "true" ]]
  then
    systemctl enable vector-service-discovery
    systemctl restart vector-service-discovery
  fi
}

run "$@"
